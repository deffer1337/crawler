# Сrawler
Авторы: Наумов Игорь, Комиссарова Юлия

# Описание возможностей приложения
- Переход по ссылкам в рамках указанных доменов [текущего, группы, etc]
- Сохранение страниц на диск в папку `Pages/`
- Отсутствие повторного скачивания страниц
- Возможность докачки
- Поддержка robots.txt
- Скачивание в несколько потоков

# Консольная версия
**Для запуска необходима версия python меньше 3.9**
Запуск программы: `c_crawler.py [sites] [OPTION]` 

`sites` - список доменов введенных через пробел

OPTIONS
- глубина поиска: `-d`

**Пример запуска:**
`c_crawler.py https://github.com/deffer1337/crawler`

# Состав
- README.md
- Консольная версия `c_crawler.py`
- Тесты `tests/`
