# Сrawler
Авторы: Наумов Игорь, Комиссарова Юлия

# Описание возможностей приложения
- Переход по ссылкам в рамках указанных доменов [текущего, группы, etc]
- Сохранение страниц на диск в папку `Pages/`
- Отсутствие повторного скачивания страниц
- Возможность докачки
- Поддержка robots.txt
- Скачивание в несколько потоков
- Скачивание напрямую в архив
- Скачивание по указанному пути
- Сохранение состояний неоконченных запусков
- Логирование

# Консольная версия
`WARNING:` **Для запуска необходима версия python меньше 3.9**

Запуск программы: `c_crawler.py [sites] [OPTION]` где `sites` - список доменов введенных через пробел

OPTIONS
- справка: `-h`, `--help`
- глубина поиска: `-d`
- сохранение в архив: `-a`
- путь до скаченных страниц: `-p`
- количество потоков для соответствующей страницы: `-t`

**Пример запуска:**
`c_crawler.py https://github.com/deffer1337/crawler`

# Состав
- README.md
- Консольная версия `c_crawler.py`
- Модули приложения `modules/`
- Тесты `tests/`
